---
sidebar_position: 5
---

# روبوٹس کے لیے کمپیوٹر وژن

وژن بلاشبہ انسانوں کے لیے سب سے اہم احساس ہے، اور یہ روبوٹس کے لیے بھی ایک اہم سینسنگ موڈیلیٹی ہے۔ کمپیوٹر وژن مصنوعی ذہانت کا وہ شعبہ ہے جو کمپیوٹرز کو بصری دنیا کو "دیکھنے" اور سمجھنے کے قابل بناتا ہے۔ اس باب میں، ہم کمپیوٹر وژن کے بنیادی اصولوں اور یہ کس طرح روبوٹس کو اپنے ماحول کو سمجھنے اور سمجھنے کے قابل بنانے کے لیے استعمال ہوتا ہے کو دریافت کریں گے۔

## روبوٹکس میں وژن کا کردار

کمپیوٹر وژن روبوٹکس ایپلی کیشنز کی ایک وسیع رینج میں استعمال ہوتا ہے، بشمول:

*   **نیویگیشن:** روبوٹ اپنے ماحول میں نیویگیٹ کرنے، رکاوٹوں سے بچنے اور نقشے بنانے کے لیے کمپیوٹر وژن کا استعمال کرتے ہیں۔
*   **ہیرا پھیری:** روبوٹ اشیاء کی شناخت اور انہیں پکڑنے کے لیے کمپیوٹر وژن کا استعمال کرتے ہیں۔
*   **انسان-روبوٹ تعامل:** روبوٹ انسانوں کو پہچاننے اور ان کے ساتھ تعامل کرنے کے لیے کمپیوٹر وژن کا استعمال کرتے ہیں۔
*   **معائنہ:** روبوٹ نقائص کے لیے مصنوعات اور انفراسٹرکچر کا معائنہ کرنے کے لیے کمپیوٹر وژن کا استعمال کرتے ہیں۔

## امیج پروسیسنگ کے بنیادی اصول

اس سے پہلے کہ ہم بصری دنیا کی تشریح کرنا شروع کریں، ہمیں امیج پروسیسنگ کے بنیادی اصولوں کو سمجھنے کی ضرورت ہے۔ ایک تصویر صرف پکسلز کی ایک 2D صف ہے، اور ہر پکسل کی ایک قدر ہوتی ہے جو اس کے رنگ یا شدت کی نمائندگی کرتی ہے۔ امیج پروسیسنگ ان پکسلز کو بڑھانے یا مفید معلومات نکالنے کے لیے ہیرا پھیری کا عمل ہے۔

کچھ عام امیج پروسیسنگ تکنیکوں میں شامل ہیں:

*   **فلٹرنگ:** فلٹرنگ کا استعمال کسی تصویر سے شور کو ہٹانے یا کچھ خصوصیات کو بڑھانے کے لیے کیا جاتا ہے۔
*   **ایج ڈیٹیکشن:** ایج ڈیٹیکشن کا استعمال کسی تصویر میں اشیاء کی حدود کی شناخت کے لیے کیا جاتا ہے۔
*   **رنگ کی جگہ کی تبدیلی:** رنگ کی جگہ کی تبدیلی کا استعمال کسی تصویر کو ایک رنگ کی جگہ سے دوسری میں تبدیل کرنے کے لیے کیا جاتا ہے، جیسے RGB سے گرے اسکیل میں۔

### OpenCV کے ساتھ ہینڈز آن

OpenCV کمپیوٹر وژن اور امیج پروسیسنگ کے لیے ایک مقبول اوپن سورس لائبریری ہے۔ یہ تصاویر اور ویڈیوز کے ساتھ کام کرنے کے لیے ٹولز اور الگورتھم کی ایک وسیع رینج فراہم کرتا ہے۔

یہ ایک سادہ مثال ہے کہ ایک تصویر کو پڑھنے اور اسے گرے اسکیل میں تبدیل کرنے کے لیے OpenCV کا استعمال کیسے کریں۔

**Python**

```python
import cv2

# Read an image
img = cv2.imread('robot_image.jpg')

# Convert to grayscale
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Display the image
cv2.imshow('Grayscale Image', gray_img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

**C++**

```cpp
#include <opencv2/opencv.hpp>
#include <iostream>

int main() {
    cv::Mat image = cv::imread("robot_image.jpg", cv::IMREAD_COLOR);
    if (image.empty()) {
        std::cout << "Could not open or find the image" << std::endl;
        return -1;
    }
    cv::imshow("Display window", image);
    cv::waitKey(0);
    return 0;
}
```

## آبجیکٹ ڈیٹیکشن اور پہچان

آبجیکٹ ڈیٹیکشن اور پہچان ایک تصویر میں اشیاء کی شناخت اور لوکلائزیشن کا کام ہے۔ یہ بہت سے روبوٹکس ایپلی کیشنز، جیسے پکڑنا اور نیویگیشن کے لیے ایک اہم صلاحیت ہے۔

آبجیکٹ ڈیٹیکشن اور پہچان کے لیے متعدد مختلف تکنیکیں ہیں، جو ہیئر کاسکیڈز جیسے روایتی طریقوں سے لے کر YOLO اور Faster R-CNN جیسے جدید گہری لرننگ پر مبنی نقطہ نظر تک ہیں۔

## سیمانٹک سیگمنٹیشن

سیمانٹک سیگمنٹیشن ایک تصویر میں ہر پکسل کو ایک زمرے میں درجہ بندی کرنے کا کام ہے، جیسے "سڑک،" "آسمان،" یا "شخص"۔ یہ روبوٹ کو صرف آبجیکٹ ڈیٹیکشن کے مقابلے میں کہیں زیادہ گہری سطح پر منظر کو سمجھنے کی اجازت دیتا ہے۔

## بیک وقت لوکلائزیشن اور میپنگ (SLAM)

بیک وقت لوکلائزیشن اور میپنگ (SLAM) ایک نامعلوم ماحول کا نقشہ بنانے کا عمل ہے جبکہ بیک وقت اس نقشے کے اندر روبوٹ کی اپنی جگہ کا بھی پتہ لگایا جاتا ہے۔ یہ روبوٹکس میں ایک بنیادی مسئلہ ہے، اور یہ خود مختار نیویگیشن کے لیے ضروری ہے۔

SLAM کی متعدد مختلف اقسام ہیں، بشمول:

*   **بصری SLAM:** بصری SLAM ماحول کا نقشہ بنانے کے لیے کیمرے کا استعمال کرتا ہے۔
*   **لِڈار SLAM:** لِڈار SLAM ماحول کا نقشہ بنانے کے لیے لِڈار سینسر کا استعمال کرتا ہے۔

| تکنیک | تفصیل | روبوٹکس میں اطلاق |
| :---------------- | :------------------------------------------------ | :---------------------------- |
| آبجیکٹ ڈیٹیکشن | تصاویر میں اشیاء کی شناخت اور لوکلائزیشن | پکڑنا، نیویگیشن |
| سیمانٹک سیگمنٹیشن | ہر پکسل کو زمرے کے لحاظ سے درجہ بندی کرنا | منظر کی سمجھ، رکاوٹوں سے بچنا |
| SLAM | بیک وقت لوکلائزیشن اور میپنگ | روبوٹ نیویگیشن اور میپنگ |

## روبوٹ وژن کے لیے گہری لرننگ

گہری لرننگ نے کمپیوٹر وژن کے میدان پر گہرا اثر ڈالا ہے، اور اس نے روبوٹس کو وژن کے بہت سے کاموں پر جدید ترین کارکردگی حاصل کرنے کے قابل بنایا ہے۔ کنولوشنل نیورل نیٹ ورکس (CNNs) گہری لرننگ ماڈل کی ایک قسم ہیں جو خاص طور پر امیج پروسیسنگ کاموں کے لیے موزوں ہیں۔

یہ TensorFlow کا استعمال کرتے ہوئے امیج کی درجہ بندی کے لیے ایک سادہ CNN آرکیٹیکچر کی ایک مثال ہے:

```python
import tensorflow as tf
from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])
model.summary()
```

گہری لرننگ کا استعمال کرتے ہوئے، ہم روبوٹ وژن سسٹمز بنا سکتے ہیں جو پہلے سے کہیں زیادہ درست، مضبوط اور عام مقصد کے ہیں۔